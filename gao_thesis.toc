\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {chapter}{\numberline {2}Reinforcement Learning}{3}
\contentsline {section}{\numberline {2.1}Markov Decision Process}{3}
\contentsline {subsection}{\numberline {2.1.1}Partially Observable Markov Decision Process}{4}
\contentsline {subsection}{\numberline {2.1.2}Markov Decision Process with Continuous States}{5}
\contentsline {subsection}{\numberline {2.1.3}Value Functions}{6}
\contentsline {subsection}{\numberline {2.1.4}Natural Actor Critic Model}{7}
\contentsline {section}{\numberline {2.2}Reinforcement Learning Methods}{8}
\contentsline {subsection}{\numberline {2.2.1}Policy Evaluation}{8}
\contentsline {subsection}{\numberline {2.2.2}Policy Gradient Methods}{9}
\contentsline {section}{\numberline {2.3}Classification of the Regarded RL Problems}{10}
\contentsline {section}{\numberline {2.4}Policy Gradient with Parameter Exploration}{11}
\contentsline {subsection}{\numberline {2.4.1}PGPE algorithm}{11}
\contentsline {chapter}{\numberline {3}Deep Recurrent Neural Networks}{17}
\contentsline {section}{\numberline {3.1}Deep Learning and its Recent Advances}{17}
\contentsline {section}{\numberline {3.2}Feedforward Neural Networks}{18}
\contentsline {section}{\numberline {3.3}Recurrent Neural Networks}{19}
\contentsline {subsection}{\numberline {3.3.1}Finite Unfolding in Time}{20}
\contentsline {subsection}{\numberline {3.3.2}Overshooting}{22}
\contentsline {subsection}{\numberline {3.3.3}Dynamical Consistency}{23}
\contentsline {section}{\numberline {3.4}Universal Approximation}{24}
\contentsline {section}{\numberline {3.5}Training of RNN}{24}
\contentsline {subsection}{\numberline {3.5.1}Shared Weight Extended Backpropagation}{25}
\contentsline {subsection}{\numberline {3.5.2}Learning Long-Term Dependencies}{25}
\contentsline {subsection}{\numberline {3.5.3}Optimization Methods}{28}
\contentsline {subsubsection}{Nesterovs Accelerated Gradient}{29}
\contentsline {subsubsection}{Adam}{29}
\contentsline {chapter}{\numberline {4}Prior Arts of Combining Deep Neuron Network and RL}{31}
\contentsline {section}{\numberline {4.1}Deep Q Network}{31}
\contentsline {chapter}{\numberline {5}Experiment}{33}
\contentsline {section}{\numberline {5.1}Cart-pole Balancing}{33}
\contentsline {subsection}{\numberline {5.1.1}System Implementation}{35}
\contentsline {subsection}{\numberline {5.1.2}Experiment Result}{35}
\contentsline {section}{\numberline {5.2}Baxter Robot Learning a Action}{37}
\contentsline {subsection}{\numberline {5.2.1}System Implementation}{37}
\contentsline {subsection}{\numberline {5.2.2}Experiment Result Using Baxter Simulator}{38}
\contentsline {subsection}{\numberline {5.2.3}Experiment Result Using Baxter Robot}{38}
\contentsline {chapter}{References}{41}
